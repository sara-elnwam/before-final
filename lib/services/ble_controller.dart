// ble_controller.dart

import 'package:flutter/material.dart';
import 'package:flutter_blue_plus/flutter_blue_plus.dart';
import 'package:permission_handler/permission_handler.dart';
import 'dart:convert'; // ğŸ’¡ ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¥Ù„Ù‰ 'dart:convert'
import 'dart:async';
import 'package:flutter/foundation.dart' show kIsWeb, kDebugMode;
import 'package:flutter_tts/flutter_tts.dart';
import 'package:speech_to_text/speech_to_text.dart';
import 'package:google_generative_ai/google_generative_ai.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:get/get.dart';
// ğŸ’¡ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ø¯Ø§Ù„Ø© firstWhereOrNull ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…
import 'package:collection/collection.dart';

import '../models/user_profile.dart';
import '../enums/action_type.dart';

// ------------------------------------------------------------------------
// Ø«ÙˆØ§Ø¨Øª Ø®Ø¯Ù…Ø© Bluetooth
// ------------------------------------------------------------------------
const String SERVICE_UUID = "4fafc201-1fb5-459e-8fcc-c5c9c331914b";
const String DATA_CHAR_UUID = "beb5483e-36e1-4688-b7f5-ea07361b26a8";
const String CONFIG_CHAR_UUID = "beb5483e-36e1-4688-b7f5-ea07361b26a7";

// ------------------------------------------------------------------------
// Ù…ÙØ§ØªÙŠØ­ SharedPreferences
// ------------------------------------------------------------------------
const String USER_PROFILE_KEY = 'user_profile_data';
const String LANGUAGE_CODE_KEY = 'language_code';
// ğŸ”‘ Ù…ÙØ§ØªÙŠØ­ Ø¥Ø¶Ø§ÙÙŠØ© Ù„ØªÙ…ÙƒÙŠÙ† Ø¯Ø§Ù„Ø© clearAllData Ù…Ù† Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„
const String USER_PROFILE_PREFS_KEY = 'userProfile';
const String GESTURE_CONFIG_PREFS_KEY = 'gestureConfig';


// ------------------------------------------------------------------------
// âš ï¸ Ù…ÙØªØ§Ø­ API Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ Gemini - ÙŠØ¬Ø¨ ØªØ¹ÙˆÙŠØ¶Ù‡ Ø¨Ù…ÙØªØ§Ø­Ùƒ Ø§Ù„ÙØ¹Ù„ÙŠ
// ------------------------------------------------------------------------
// âŒ ØªÙ€Ù†Ù€Ø¨Ù€ÙŠÙ€Ù‡: Ù‡Ø°Ø§ Ø§Ù„Ù…ÙØªØ§Ø­ ÙˆÙ‡Ù…ÙŠ ("AIzaSyBwOMGLGl6GJsKkgvyT2Mz57vmdNWhOZJI") ÙˆÙ‡Ùˆ Ø³Ø¨Ø¨ ÙØ´Ù„ Ø®Ø¯Ù…Ø§Øª Gemini Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØ§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©.
// ÙŠØ¬Ø¨ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ù…ÙØªØ§Ø­ API Ø­Ù‚ÙŠÙ‚ÙŠ Ø®Ø§Øµ Ø¨Ùƒ Ù„ÙƒÙŠ ØªØ¹Ù…Ù„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.
const String GEMINI_API_KEY = "AIzaSyBwOMGLGl6GJsKkgvyT2Mz57vmdNWhOZJI"; // Ù…ÙØªØ§Ø­ ÙˆÙ‡Ù…ÙŠ

// ------------------------------------------------------------------------
// Ø«ÙˆØ§Ø¨Øª Ø§Ù„ØªÙ†Ù‚Ù„ Ø§Ù„ØµÙˆØªÙŠ (Ù„Ù†Ù…ÙˆØ°Ø¬ Gemini)
// ------------------------------------------------------------------------
const Map<String, String> _AVAILABLE_SCREENS = {
  'profile': '/profile',
  'settings': '/profile', // Alias
  'sign up': '/profile', // Alias
  'allergies': '/allergies',
  'bluetooth': '/bluetooth',
  'connect': '/bluetooth', // Alias
  'gestures': '/gestures',
  'voice': '/tts_stt',
  'language': '/tts_stt', // Alias
  'home': '/home',
  'main': '/home', // Alias
};


class BleController extends GetxController {
  // ------------------------------------------------------------------------
  // 1. Services & Variables
  // ------------------------------------------------------------------------
  final FlutterTts _flutterTts = FlutterTts();
  final SpeechToText _speechToText = SpeechToText();

  bool _isListening = false;
  bool get isListening => _isListening;

  String _lastWords = '';
  String get lastWords => _lastWords;

  bool _speechToTextInitialized = false;

  late final GenerativeModel _chatModel;
  late final GenerativeModel _navigationModel;

  Timer? _sttTimeoutTimer;
  // ğŸ”‘ ØªÙ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„: Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ù‡Ù„Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ø¥Ø¯Ø®Ø§Ù„ Ø£ÙˆØ§Ù…Ø± Ø£Ø·ÙˆÙ„
  final Duration _maxListeningDuration = const Duration(seconds: 15);
  // final Duration _sttTimeoutDuration = const Duration(seconds: 3); // ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø­Ø§Ù„ÙŠØ§Ù‹

  final SharedPreferences _prefs;

  bool _isAppInitialized = false;
  bool get isAppInitialized => _isAppInitialized;

  // ------------------------------------------------------------------------
  // 2. User Profile & Locale Logic
  // ------------------------------------------------------------------------
  UserProfile? _userProfile;
  UserProfile? get userProfile => _userProfile;
  // ğŸ”‘ ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± userProfile Ù„ÙƒÙŠ Ù„Ø§ ÙŠØ­Ø¯Ø« ØªØ¶Ø§Ø±Ø¨ Ù…Ø¹ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¶Ø§ÙØ©
  set userProfile(UserProfile? profile) {
    _userProfile = profile;
  }

  bool get isUserRegistered => _userProfile != null;

  // ğŸ’¡ ÙŠØ¬Ø¨ Ø£Ù† ØªØ³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ§Ù„ Ù‚ÙŠÙ… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ ÙƒØ§ÙØªØ±Ø§Ø¶ÙŠ
  double get speechRate => _userProfile?.speechRate ?? 0.5;
  double get volume => _userProfile?.volume ?? 1.0;
  String get assistantVoice => _userProfile?.assistantVoice ?? '';

  String _currentLanguageCode = 'en-US';
  String get currentLanguageCode => _currentLanguageCode;
  String get localeCode => _currentLanguageCode;

  String get languageCode => _currentLanguageCode.split('-').first;
  String? get countryCode => _currentLanguageCode.split('-').length > 1 ? _currentLanguageCode.split('-')[1] : null;

  Map<String, ActionType> _gestureConfig = {
    'shakeTwiceAction': ActionType.sos_emergency,
    'tapThreeTimesAction': ActionType.call_contact,
    'longPressAction': ActionType.disable_feature,
  };
  Map<String, ActionType> get gestureConfig => _gestureConfig;

  // Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨Ù„ÙˆØªÙˆØ«... (Ù„Ù… ÙŠØªÙ… ØªØºÙŠÙŠØ±Ù‡Ø§)
  final List<ScanResult> scanResults = [];
  BluetoothDevice? connectedDevice;
  bool _isScanning = false;
  bool _isConnecting = false;
  String _receivedDataMessage = 'No data received yet.';
  StreamSubscription<List<int>>? _dataSubscription;

  bool get isScanning => _isScanning;
  bool get isConnecting => _isConnecting;
  String get receivedDataMessage => _receivedDataMessage;
  bool get isConnected => connectedDevice != null;


  // ------------------------------------------------------------------------
  // 3. Constructor & Initialization
  // ------------------------------------------------------------------------
  BleController({required SharedPreferences prefs}) : _prefs = prefs {
    // ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Gemini
    final String apiKey = (GEMINI_API_KEY.isEmpty || GEMINI_API_KEY == 'AIzaSyBwOMGLGl6GJsKkgvyT2Mz57vmdNWhOZJI')
        ? 'DUMMY_KEY' : GEMINI_API_KEY;

    _chatModel = GenerativeModel(
      model: 'gemini-2.5-flash',
      apiKey: apiKey,
    );
    _navigationModel = GenerativeModel(
      model: 'gemini-2.5-flash',
      apiKey: apiKey,
    );
    if (apiKey == 'DUMMY_KEY' && kDebugMode) {
      print("ğŸš¨ Warning: Gemini API Key is not set or is DUMMY_KEY. Voice commands may fail.");
    }
  }

  // ğŸ”‘ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ _initStt ÙÙŠ onInit Ù„Ø¶Ù…Ø§Ù† Ø¬Ø§Ù‡Ø²ÙŠØ© Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª Ù…Ø¨ÙƒØ±Ø§Ù‹
  @override
  void onInit() {
    super.onInit();
    _initStt(); // ØªÙ‡ÙŠØ¦Ø© STT ÙˆØ§Ù„Ø£Ø°ÙˆÙ†Ø§Øª
    initializeController(); // Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒÙ„ÙŠØ©
  }


  Future<void> loadUserProfile() async {
    await _loadUserProfile();
    update();
  }

  Future<void> initializeController() async {
    await _loadUserProfile();

    final String? savedLang = _prefs.getString(LANGUAGE_CODE_KEY);

    // ØªÙˆØ­ÙŠØ¯ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù€ locale
    String initialLocale = savedLang ?? _userProfile?.localeCode ?? Get.deviceLocale?.toString() ?? 'en_US';
    initialLocale = initialLocale.replaceAll('_', '-');
    if (initialLocale.length == 2) {
      initialLocale = initialLocale == 'ar' ? 'ar-SA' : 'en-US';
    }

    _currentLanguageCode = initialLocale;

    if (_userProfile != null) {
      // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
      _userProfile = _userProfile!.copyWith(localeCode: _currentLanguageCode);
      await saveUserProfile(_userProfile!, updateLocale: false);
    }

    await _configureTtsSettings();

    final parts = _currentLanguageCode.split('-');
    Get.updateLocale(Locale(parts[0], parts.length > 1 ? parts[1] : null));

    // _initStt ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡ ÙÙŠ onInitØŒ Ù‡Ù†Ø§ Ù†Ø¶Ù…Ù† Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    if(!_speechToTextInitialized) {
      await initSpeech();
    }

    _isAppInitialized = true;
    update();
    if (kDebugMode) print("Controller initialized. Locale set to: $_currentLanguageCode");
  }

  Future<void> _loadUserProfile() async {
    final String? jsonString = _prefs.getString(USER_PROFILE_KEY);
    if (jsonString != null && jsonString.isNotEmpty) {
      try {
        // ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… jsonDecode Ø§Ù„Ù…ØªØ§Ø­ Ø¨Ø¹Ø¯ ØªØµØ­ÙŠØ­ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
        final Map<String, dynamic> jsonMap = jsonDecode(jsonString);
        _userProfile = UserProfile.fromJson(jsonMap);
        _gestureConfig = {
          'shakeTwiceAction': ActionTypeExtension.fromCodeName(_userProfile!.shakeTwiceAction),
          'tapThreeTimesAction': ActionTypeExtension.fromCodeName(_userProfile!.tapThreeTimesAction),
          'longPressAction': ActionTypeExtension.fromCodeName(_userProfile!.longPressAction),
        };
        if (kDebugMode) print("UserProfile loaded successfully.");
      } catch (e) {
        if (kDebugMode) print("Error loading UserProfile: $e");
        _userProfile = null;
      }
    } else {
      _userProfile = null;
    }
  }

  // ----------------------------------------------------------------------
  // ğŸŒ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„ØºØ© ÙˆØ§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ
  // ----------------------------------------------------------------------

  void updateLocale(Locale locale) {
    final newLanguageCode = '${locale.languageCode}-${locale.countryCode}';
    _currentLanguageCode = newLanguageCode;
    Get.updateLocale(locale);
    update();
  }

  // ğŸ”‘ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: ØªØºÙŠÙŠØ± Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ Ù„ÙŠÙ‚Ø¨Ù„ Ù…ØªØºÙŠØ±ÙŠÙ† Ù…ÙˆØ¶Ø¹ÙŠÙŠÙ† (localeCode, voiceName)
  Future<void> setLocaleAndTTS(String localeCode, String voiceName) async {
    final parts = localeCode.split('-');
    final locale = Locale(parts[0], parts.length > 1 ? parts[1] : null);

    // Ø­ÙØ¸ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    _currentLanguageCode = localeCode;
    Get.updateLocale(locale);
    await _prefs.setString(LANGUAGE_CODE_KEY, localeCode);

    if (_userProfile != null) {
      // ØªØ­Ø¯ÙŠØ« ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ Ø¨Ø§Ù„Ù„ØºØ© ÙˆØ§Ù„ØµÙˆØª Ø§Ù„Ø¬Ø¯ÙŠØ¯ÙŠÙ†
      final updatedProfile = _userProfile!.copyWith(
        localeCode: localeCode,
        assistantVoice: voiceName,
      );
      await saveUserProfile(updatedProfile, updateLocale: false);
    } else {
      // ÙÙ‚Ø· Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª TTS Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù…Ù„Ù Ø´Ø®ØµÙŠ
      await _configureTtsSettings();
    }

    update();
  }


  Future<bool> saveUserProfile(UserProfile profile, {bool updateLocale = true}) async {
    try {
      // ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… jsonEncode Ø§Ù„Ù…ØªØ§Ø­ Ø¨Ø¹Ø¯ ØªØµØ­ÙŠØ­ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
      final jsonString = jsonEncode(profile.toJson());
      await _prefs.setString(USER_PROFILE_KEY, jsonString);
      // ğŸ”‘ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù…ÙØªØ§Ø­ Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ØªÙ…ÙƒÙŠÙ† Ù…Ù† Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø´Ø§Ù…Ù„ ÙÙŠ clearAllData
      await _prefs.setString(USER_PROFILE_PREFS_KEY, jsonString);

      _userProfile = profile;

      _gestureConfig = {
        'shakeTwiceAction': ActionTypeExtension.fromCodeName(profile.shakeTwiceAction),
        'tapThreeTimesAction': ActionTypeExtension.fromCodeName(profile.tapThreeTimesAction),
        'longPressAction': ActionTypeExtension.fromCodeName(profile.longPressAction),
      };

      if (updateLocale) {
        _currentLanguageCode = profile.localeCode;
        await _prefs.setString(LANGUAGE_CODE_KEY, profile.localeCode);
        final parts = _currentLanguageCode.split('-');
        Get.updateLocale(Locale(parts[0], parts.length > 1 ? parts[1] : null));
      }

      await _configureTtsSettings();
      update();

      if (kDebugMode) print("UserProfile saved: ${profile.fullName}");
      return true;
    } catch (e) {
      if (kDebugMode) print("CRITICAL ERROR: Failed to save user profile: $e");
      // ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… .tr Ù‡Ù†Ø§ Ù„Ù„Ø§ÙØªØ±Ø§Ø¶ Ø¨ÙˆØ¬ÙˆØ¯ ØªØ¹Ø±ÙŠØ¨
      await speak("profile_save_failed".tr);
      return false;
    }
  }

  Future<void> _clearUserData() async {
    _userProfile = null;
    await _prefs.remove(USER_PROFILE_KEY);
    await _prefs.remove(LANGUAGE_CODE_KEY);
    // ğŸ”‘ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ
    await _prefs.remove(USER_PROFILE_PREFS_KEY);
    await _prefs.remove(GESTURE_CONFIG_PREFS_KEY); // Ø¥Ø²Ø§Ù„Ø© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¥ÙŠÙ…Ø§Ø¡Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„

    _currentLanguageCode = 'en-US';
    Get.updateLocale(const Locale('en', 'US'));

    update();
  }

  Future<void> clearUserProfile() async {
    await _clearUserData();
    await speak("profile_cleared_message".tr);
  }

  Future<void> clearUserProfileAndLogout() async {
    await _clearUserData();
  }

  // ğŸ”‘ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬ ÙˆÙ…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù„Ø­Ù„ Ø§Ù„Ø®Ø·Ø£: The method 'clearAllData' isn't defined)
  Future<void> clearAllData() async {
    // ğŸ’¡ Ø¥Ø²Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
    await _prefs.remove(USER_PROFILE_KEY);
    await _prefs.remove(LANGUAGE_CODE_KEY);
    await _prefs.remove(USER_PROFILE_PREFS_KEY);
    await _prefs.remove(GESTURE_CONFIG_PREFS_KEY);

    // Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØªØ­ÙƒÙ…
    userProfile = null; // Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ ÙÙŠ Ø§Ù„Ù…ØªØ­ÙƒÙ…
    _currentLanguageCode = 'en-US';
    Get.updateLocale(const Locale('en', 'US'));

    // Ø¥ÙŠÙ‚Ø§Ù Ø£ÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø¨Ù„ÙˆØªÙˆØ« Ø£Ùˆ Ø§Ø³ØªÙ…Ø§Ø¹
    stopListening(shouldSpeakStop: false);
    if (connectedDevice != null) {
      await disconnect(); // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© Ø§Ù„ÙØµÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
    }

    _isAppInitialized = false; // Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ù† Ø§Ù„Ù…ÙÙŠØ¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ…Ù‡ÙŠØ¯ Ù„Ø§Ø­Ù‚Ø§Ù‹

    update(); // Ù„ØªØ­Ø¯ÙŠØ« Ø£ÙŠ ÙˆØ§Ø¬Ù‡Ø§Øª Ù…Ø³ØªØ®Ø¯Ù… ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØªØ­ÙƒÙ…
    if (kDebugMode) print("All user data and connections cleared.");
  }


  // ------------------------------------------------------------------------
  // 4. TTS & STT Logic (Enhancements)
  // ------------------------------------------------------------------------

  Future<void> _configureTtsSettings() async {
    await _flutterTts.stop();

    try {
      await _flutterTts.setLanguage(_currentLanguageCode);

      if (_userProfile?.assistantVoice != null && _userProfile!.assistantVoice.isNotEmpty) {
        // ÙŠØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
        List<dynamic> voices = await _flutterTts.getVoices;
        dynamic matchingVoice;

        final String targetVoiceKey = _userProfile!.assistantVoice;
        final String currentLocale = _currentLanguageCode;
        final String currentLanguage = _currentLanguageCode.split('-').first;

        // Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¹Ù† Ø§Ù„ØµÙˆØª
        if (targetVoiceKey.toLowerCase() == 'kore') {
          matchingVoice = voices.firstWhereOrNull(
                (v) => v['name'].toString().toLowerCase().contains('kore'),
          );
        } else if (targetVoiceKey.toLowerCase() == 'male') {
          // ğŸ”‘ Ø¨Ø­Ø« Ø§Ø­ØªØ±Ø§ÙÙŠ: Ø¹Ù† ØµÙˆØª Ø°ÙƒØ± Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ØºØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Ø£Ùˆ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)
          matchingVoice = voices.firstWhereOrNull(
                (v) => (v['gender'] == 'male' || v['name'].toString().toLowerCase().contains('male'))
                && (v['locale'] == currentLocale || v['locale'].toString().startsWith(currentLanguage)),
          );
        } else if (targetVoiceKey.toLowerCase() == 'female') {
          // ğŸ”‘ Ø¨Ø­Ø« Ø§Ø­ØªØ±Ø§ÙÙŠ: Ø¹Ù† ØµÙˆØª Ø£Ù†Ø«Ù‰ Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ØºØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Ø£Ùˆ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)
          matchingVoice = voices.firstWhereOrNull(
                (v) => (v['gender'] == 'female' || v['name'].toString().toLowerCase().contains('female'))
                && (v['locale'] == currentLocale || v['locale'].toString().startsWith(currentLanguage)),
          );
        } else {
          // Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØµÙˆØª Ø¨Ø§Ø³Ù… Ù…Ø­Ø¯Ø¯
          matchingVoice = voices.firstWhereOrNull(
                (v) => v['name'] == targetVoiceKey && v['locale'] == currentLocale,
          );
        }

        if (matchingVoice != null) {
          // ğŸ’¡ ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… .cast Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ ÙˆÙ‚Øª Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ·Ø©
          await _flutterTts.setVoice(matchingVoice.cast<String, String>());
        } else {
          // Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø©ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø£ÙˆÙ„ ØµÙˆØª Ù…ØªØ§Ø­ Ù„Ù„ØºØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
          final firstMatch = voices.firstWhereOrNull((v) => v['locale'] == currentLocale);
          if (firstMatch != null) {
            await _flutterTts.setVoice(firstMatch.cast<String, String>());
          }
        }
      }
    } catch (e) {
      if (kDebugMode) print("Warning: Could not set TTS language to $_currentLanguageCode. $e");
    }

    await _flutterTts.setSpeechRate(speechRate);
    await _flutterTts.setVolume(volume);
  }

  // âŒ Ù„Ù… ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù‡Ù†Ø§ØŒ Ø¨Ù„ ØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± Ø§ÙƒØªÙ…Ø§Ù„Ø§Ù‹
  Future<void> updateTtsSettings({double? rate, double? vol, String? locale}) async {
    if (_userProfile == null) return;

    final updatedProfile = _userProfile!.copyWith(
      speechRate: rate,
      volume: vol,
      localeCode: locale,
    );
    // saveUserProfile Ø³ÙŠÙ†ÙØ° _configureTtsSettings
    await saveUserProfile(updatedProfile);
  }

  // ğŸ”‘ Ø¯Ø§Ù„Ø© ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙˆØª: ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØª Ø«Ù… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ saveUserProfile Ø§Ù„Ø°ÙŠ ÙŠÙ†ÙØ° _configureTtsSettings
  Future<void> updateAssistantVoice(String voiceKey) async {
    if (_userProfile == null) return;

    final updatedProfile = _userProfile!.copyWith(
      assistantVoice: voiceKey,
    );
    await saveUserProfile(updatedProfile, updateLocale: false);
    // ğŸ’¡ ØªØ£ÙƒÙŠØ¯ Ø¥Ø¶Ø§ÙÙŠ Ø¨Ø£Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ØªÙ… ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø­ÙØ¸ (Ø¹Ø¨Ø± saveUserProfile -> _configureTtsSettings)
    if (kDebugMode) print("Assistant voice set to $voiceKey and TTS settings configured immediately.");
  }

  /// Ù†Ø·Ù‚ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø¨Ø¹Ø¯ Ø¥ÙŠÙ‚Ø§Ù Ø£ÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ø³ØªÙ…Ø§Ø¹ Ø£Ùˆ Ù†Ø·Ù‚
  Future<void> speak(String text, {String? localeCode, String? voice}) async {
    // ğŸ”‘ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ø§Ø³Ù… 1: Ø¥ÙŠÙ‚Ø§Ù Ø£ÙŠ Ù†Ø·Ù‚ Ø³Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø¹ Ø§Ù„ØªØ¯Ø§Ø®Ù„ (Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø³ÙŠØ§Ù‚)
    await _flutterTts.stop();

    if (_speechToText.isListening) {
      // ğŸ’¡ Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… stopListening Ù‡Ù†Ø§ØŒ Ø§Ø³ØªØ®Ø¯Ù… stop() Ù…Ø¨Ø§Ø´Ø±Ø© Ù„ØªØ¬Ù†Ø¨ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ
      await _speechToText.stop();
      _isListening = false;
      update();
    }

    _flutterTts.setCompletionHandler(() {
      update();
    });

    // ğŸ”‘ ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ®ØµÙŠØµ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© (Ø§Ù„Ø³Ø±Ø¹Ø©ØŒ Ø§Ù„Ø­Ø¬Ù…ØŒ Ø§Ù„ØµÙˆØª)
    await _configureTtsSettings();

    // ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… .tr Ù‡Ù†Ø§ Ù„Ù„Ø§ÙØªØ±Ø§Ø¶ Ø¨ÙˆØ¬ÙˆØ¯ ØªØ¹Ø±ÙŠØ¨
    await _flutterTts.speak(text.tr);
    update();
  }

  Future<void> stop() async {
    await _flutterTts.stop();
  }

  // ------------------------------------------------------------------------
  // ğŸ™ï¸ STT Logic (Speech-to-Text) - Robust Initialization
  // ------------------------------------------------------------------------

  // ğŸ”‘ Ø¯Ø§Ù„Ø© ØªÙ‡ÙŠØ¦Ø© STT ÙˆÙ…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª
  Future<void> _initStt() async {
    if (kIsWeb) {
      _speechToTextInitialized = true;
      return;
    }

    // 1. Ø·Ù„Ø¨ Ø¥Ø°Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
    final status = await Permission.microphone.request();

    if (status.isGranted) {
      await initSpeech();
    } else {
      // Ø¥Ø´Ø¹Ø§Ø± ØµÙˆØªÙŠ ÙÙŠ Ø­Ø§Ù„ Ø±ÙØ¶ Ø§Ù„Ø¥Ø°Ù†
      await speak('microphone_permission_denied_tts'.tr);
      if (kDebugMode) print("Microphone permission denied.");
    }
  }


  Future<void> initSpeech() async {
    if (_speechToTextInitialized) return;

    try {
      if (kIsWeb) {
        _speechToTextInitialized = true;
        return;
      }

      final isAvailable = await _speechToText.initialize(
        onError: (e) {
          if (kDebugMode) print('STT Error: ${e.errorMsg}');
          _isListening = false;
          _sttTimeoutTimer?.cancel();
          update();
          speak("speech_recognition_error".tr);
        },
        onStatus: (status) {
          if (kDebugMode) print('STT Status: $status');
          if (status == 'listening') {
            _isListening = true;
          } else if (status == 'notListening') {
            _isListening = false;
            // ÙŠØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ø¤Ù‚Øª Ø¹Ù†Ø¯ Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ Ø£Ùˆ Ø§Ù„Ù‚Ø³Ø±ÙŠ
            _sttTimeoutTimer?.cancel();
          }
          update();
        },
      );

      if (isAvailable) {
        _speechToTextInitialized = true;
        if (kDebugMode) print("SpeechToText initialized successfully.");
      } else {
        if (kDebugMode) print("SpeechToText not available or permissions denied.");
        speak("speech_not_available".tr);
      }
    } catch (e) {
      if (kDebugMode) print("Critical STT Initialization Error: $e");
      speak("speech_initialization_error".tr);
    } finally {
      update();
    }
  }

  /// Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
  Future<void> startListening({required Function(String) onResult}) async {
    if (!_speechToTextInitialized) {
      await _initStt(); // Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø·Ù„Ø¨ Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
      if (!_speechToTextInitialized) {
        await speak("speech_recognition_error".tr);
        return;
      }
    }

    if (_isListening) return;

    _lastWords = '';
    _isListening = true;
    update();

    _sttTimeoutTimer?.cancel();
    // ğŸ”‘ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù‡Ù„Ø©: Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© Ø®Ù„Ø§Ù„ Ø£Ù‚ØµÙ‰ Ù…Ø¯Ø©ØŒ Ù‚Ù… Ø¨ØªÙ†ÙÙŠØ° Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¬Ø²Ø¦ÙŠØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø©.
    _sttTimeoutTimer = Timer(_maxListeningDuration, () {
      if (kDebugMode) print("STT Timeout reached. Processing last words.");
      // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù‚Ø³Ø±Ø§Ù‹ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
      stopListening(shouldSpeakStop: false);
      onResult(_lastWords);
      speak('listening_timeout_prompt'.tr);
    });

    try {
      await _speechToText.listen(
        onResult: (result) {
          _lastWords = result.recognizedWords;
          update();

          if (result.finalResult) {
            // ğŸ”‘ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ ÙÙˆØ± Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Ù†Ù‡Ø§Ø¦ÙŠØ©
            _sttTimeoutTimer?.cancel();
            stopListening(shouldSpeakStop: false);
            onResult(_lastWords);
          }
        },
        localeId: _currentLanguageCode,
        listenFor: _maxListeningDuration,
      );
    } catch (e) {
      if (kDebugMode) print("Error during listening: $e");
      _sttTimeoutTimer?.cancel();
      stopListening(shouldSpeakStop: false);
      onResult('');
      await speak("speech_recognition_error".tr);
    }
  }

  /// Ø¥ÙŠÙ‚Ø§Ù Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
  void stopListening({bool shouldSpeakStop = true}) {
    _sttTimeoutTimer?.cancel();
    if (_speechToText.isListening) {
      // ğŸ’¡ ÙŠØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø¯Ù…Ø©
      _speechToText.stop();
    }
    if (_isListening) {
      _isListening = false;
      update();
      if (shouldSpeakStop) {
        // ğŸ’¡ ÙŠÙ…ÙƒÙ† Ù‡Ù†Ø§ Ø¥Ø¶Ø§ÙØ© Ù†Ø·Ù‚ "ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„"
      }
    }
  }

  // ----------------------------------------------------------------------
  // ğŸ§  Gemini Integration (Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„ØªÙ†Ù‚Ù„)
  // ----------------------------------------------------------------------

  /// Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø£ÙŠ Ø´Ø§Ø´Ø©
  Future<String> processVoiceCommand(String text) async {
    if (GEMINI_API_KEY.isEmpty || GEMINI_API_KEY == 'AIzaSyBwOMGLGl6GJsKkgvyT2Mz57vmdNWhOZJI') {
      return "gemini_not_configured".tr;
    }

    final profile = _userProfile;
    final languageCode = _currentLanguageCode.split('-').first;
    final languageName = languageCode == 'ar' ? 'Arabic' : 'English';

    final String systemInstruction = '''
    You are an AI assistant specialized for blind and visually impaired users, providing brief, actionable, and voice-friendly responses. 
    The user is named ${profile?.fullName ?? 'User'}. They are ${profile?.age.toString() ?? 'unknown'} years old. 
    Your tasks are:
    1. **Execute Commands:** If the request is a simple command (like 'call contact' or 'SOS'), respond with a confirmation phrase, but do not execute the action yourself.
    2. **Answer Questions:** If the request is a general question, answer it concisely.
    3. **Use Context:** If the request relates to their age or name, provide the requested information.
    4. **If the request is nonsensical or unclear, ask the user to repeat the command.**
    Respond in the user's current language: $languageName. Keep the response brief and direct.
    ''';

    try {
      final response = await _chatModel.generateContent(
        [
          Content.system(systemInstruction),
          Content.text(text),
        ],
      );
      return response.text ?? 'no_response_received'.tr;
    } catch (e) {
      if (kDebugMode) {
        print("Gemini Chat Error: $e");
      }
      return 'smart_assistant_error'.tr;
    }
  }


  Future<String> processAllergyCommand(String query) async {
    if (GEMINI_API_KEY.isEmpty || GEMINI_API_KEY == 'AIzaSyBwOMGLGl6GJsKkgvyT2Mz57vmdNWhOZJI') {
      return "gemini_not_configured".tr;
    }

    const List<String> availableAllergens = [
      'Peanut', 'Milk / Dairy', 'Egg', 'Soybean', 'Wheat / Gluten',
      'Other Food', 'Shellfish', 'Fish', 'Cat Dander', 'Dog Dander',
      'Rodent', 'Other Pet', 'Antibiotics', 'Anesthetics',
      'Insect Sting Venom', 'NSAIDs', 'Other Medication', 'Pollen',
      'Dust Mites', 'Mold', 'Cockroach', 'Smoke / Fumes', 'Other Env'
    ];
    final String allergenList = availableAllergens.join(', ');

    final String systemInstruction = '''
    You are an AI command parser for a blind user's device. Your *only* function is to interpret the user's voice command regarding allergies and output a structured command.
    The list of valid allergens is: $allergenList.
    
    Rules for output:
    1. **ACTION:** Determine if the user wants to 'ADD' or 'REMOVE' one or more allergens.
    2. **OUTPUT FORMAT:** The response *must* start with 'ALLERGY_UPDATE:' followed by the action and a comma-separated list of the *exact* allergen names from the list above.
    3. **If the command is unclear or asks a question, respond with a short phrase in the user's language (e.g., 'Please specify which allergy to add.') and do not use the ALLERGY_UPDATE: prefix.**

    Example Commands and Outputs:
    - User: "Add milk and egg." -> Output: "ALLERGY_UPDATE:ADD:Milk / Dairy,Egg"
    - User: "Remove peanut allergy." -> Output: "ALLERGY_UPDATE:REMOVE:Peanut"
    
    Respond in a single, unformatted line.
    ''';

    try {
      final response = await _chatModel.generateContent(
        [
          Content.system(systemInstruction),
          Content.text(query),
        ],
      );
      return response.text?.trim() ?? 'no_response_received'.tr;
    } catch (e) {
      if (kDebugMode) {
        print("Gemini Allergy Error: $e");
      }
      return 'smart_assistant_error'.tr;
    }
  }

  /// Ø¯Ø§Ù„Ø© Ø·Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ù…Ù† Gemini ÙˆØ§Ù„Ù†Ø·Ù‚ Ø¨Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø©
  // ğŸ”‘ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ø§Ø³Ù…: ØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ Ù„ÙŠØ±Ø¬Ø¹ Future<String>
  Future<String> getGeminiResponse(String prompt) async {
    stopListening(shouldSpeakStop: false);
    await speak("processing_command".tr);
    final geminiText = await processVoiceCommand(prompt);
    await speak(geminiText);

    // ğŸ’¡ Ø§Ù„Ø¢Ù† Ù†Ø±Ø¬Ø¹ Ù†Øµ Ø§Ù„Ø±Ø¯
    return geminiText;
  }

  // ----------------------------------------------------------------------
  // ğŸš€ Gemini Navigation Logic (Ù…Ù†Ø·Ù‚ Ø§Ù„ØªÙ†Ù‚Ù„ Ø§Ù„ØµÙˆØªÙŠ)
  // ----------------------------------------------------------------------

  /// Ø¯Ø§Ù„Ø© Ø¯Ø§Ø®Ù„ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ù…Ø± Ø§Ù„ØªÙ†Ù‚Ù„ Ø§Ù„ØµÙˆØªÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Gemini
  Future<Map<String, String>> _parseVoiceCommand(String query) async {
    if (GEMINI_API_KEY.isEmpty || GEMINI_API_KEY == 'AIzaSyBwOMGLGl6GJsKkgvyT2Mz57vmdNWhOZJI') {
      return {'action': 'UNKNOWN', 'target': 'ERROR'};
    }

    final languageCode = _currentLanguageCode.split('-').first;
    final screenKeys = _AVAILABLE_SCREENS.keys.toList().join(', ');

    final String systemInstruction = '''
    You are an AI command parser for navigation in a voice-controlled application. Your *only* function is to interpret the user's voice command and output a structured JSON instruction.

    The user speaks in language code: $languageCode.
    Available screen keys are: $screenKeys.
    The user can also say commands like 'go back' or 'return'.

    Rules for output:
    1. **ACTION:** Determine the user's intent: 'NAVIGATE', 'RETURN', or 'UNKNOWN'.
    2. **TARGET:** If 'NAVIGATE', use the exact screen key (lowercase) from the list. If 'RETURN', use 'back'. If 'UNKNOWN', use 'NOT_APPLICABLE'.
    3. **OUTPUT FORMAT:** The response *must* be a single JSON object: {"action": "ACTION_TYPE", "target": "TARGET_NAME"}.
    
    Respond in a single, unformatted line containing only the JSON object.
    ''';

    try {
      final response = await _navigationModel.generateContent(
        [
          Content.system(systemInstruction),
          Content.text(query),
        ],
      );

      String jsonText = response.text!.trim();
      // ØªÙ†Ø¸ÙŠÙ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ JSON
      jsonText = jsonText.replaceAll('```json', '').replaceAll('```', '').trim();

      // ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… json.decode Ø§Ù„Ù…ØªØ§Ø­ Ø¨Ø¹Ø¯ ØªØµØ­ÙŠØ­ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
      final Map<String, dynamic> result = json.decode(jsonText);
      return {
        'action': result['action'] as String,
        'target': result['target'] as String,
      };

    } catch (e) {
      if (kDebugMode) {
        print("Gemini Navigation Error: $e");
      }
      return {'action': 'UNKNOWN', 'target': 'ERROR'};
    }
  }


  /// Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ù…Ø± Ø§Ù„ØªÙ†Ù‚Ù„ ÙˆØªÙ†ÙÙŠØ°Ù‡ ÙˆØ§Ù„Ù†Ø·Ù‚ Ø¨Ø§Ù„Ù†ØªÙŠØ¬Ø©.
  Future<String> handleNavigationCommand(String voiceCommand) async {
    // 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØµÙˆØªÙŠ
    final parsedCommand = await _parseVoiceCommand(voiceCommand);
    final action = parsedCommand['action'];
    final target = parsedCommand['target'];

    // 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ù…Ø± Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ø®Ù„Ù
    if (action == 'RETURN' && target == 'back') {
      if (Get.previousRoute.isNotEmpty) {
        Get.back();
        return 'going_back'.tr;
      } else {
        return 'screen_not_found'.tr; // ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ø³Ø§Ù„Ø© Ù…Ø®ØªÙ„ÙØ© Ù„Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø§Ø± Ø³Ø§Ø¨Ù‚
      }
    }

    // 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ù…Ø± Ø§Ù„ØªÙ†Ù‚Ù„ Ù„Ø´Ø§Ø´Ø© Ù…Ø­Ø¯Ø¯Ø©
    if (action == 'NAVIGATE') {
      final String? targetPath = _AVAILABLE_SCREENS[target];

      if (targetPath != null) {
        Get.toNamed(targetPath);

        // ØªØ±Ø¬Ù…Ø© Ø§Ø³Ù… Ø§Ù„Ø´Ø§Ø´Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù…ØªÙˆÙØ±Ø©
        final screenName = target!.tr;
        return 'navigating_to'.trParams({'screen': screenName});
      } else {
        return 'screen_not_found'.tr;
      }
    } else {
      // UNKNOWN Ø£Ùˆ ERROR
      return 'navigation_parse_error'.tr;
    }
  }

  // ------------------------------------------------------------------------
  // 5. Bluetooth Logic
  // ------------------------------------------------------------------------

  Future<void> startScan() async {
    if (!kIsWeb) {
      Map<Permission, PermissionStatus> statuses = await [
        Permission.location,
        Permission.bluetoothScan,
        Permission.bluetoothConnect,
      ].request();
      if (statuses.values.any((s) => s != PermissionStatus.granted)) {
        await speak("bluetooth_permissions_denied".tr);
        return;
      }
    }
    if (!await FlutterBluePlus.isSupported) {
      await speak("bluetooth_not_supported".tr);
      return;
    }
    if (await FlutterBluePlus.adapterState.first != BluetoothAdapterState.on) {
      await speak("bluetooth_not_enabled".tr);
      return;
    }
    if (_isScanning) return;
    _isScanning = true;
    scanResults.clear();
    update();
    await speak("scanning_for_devices".tr);
    try {
      await FlutterBluePlus.startScan(
        withServices: [Guid(SERVICE_UUID)],
        timeout: const Duration(seconds: 4),
      );
      FlutterBluePlus.scanResults.listen((results) {
        for (ScanResult r in results) {
          if (!scanResults.any((e) => e.device.remoteId == r.device.remoteId)) {
            scanResults.add(r);
          }
        }
        update();
      });
    } catch (e) {
      if (kDebugMode) print("Scan Error: $e");
      await speak("scan_error_occurred".tr);
    } finally {
      await FlutterBluePlus.stopScan();
      _isScanning = false;
      update();
      if (scanResults.isEmpty) {
        await speak("no_devices_found".tr);
      } else {
        await speak("found_devices_count".trParams({'count': scanResults.length.toString()}));
      }
    }
  }

  Future<void> stopScan() async {
    if (_isScanning) {
      await FlutterBluePlus.stopScan();
      _isScanning = false;
      update();
      if (kDebugMode) print("Manual scan stop requested.");
    }
  }

  Future<void> connect(BluetoothDevice device) async {
    if (_isConnecting) return;
    _isConnecting = true;
    update();
    await speak("connecting_to_device".trParams({'device': device.platformName}));

    try {
      await device.connect(
        timeout: const Duration(seconds: 5),
      );
      connectedDevice = device;
      _isConnecting = false;
      await _subscribeToDataCharacteristic(device);
      await speak("connected_successfully".tr);
    } catch (e) {
      if (kDebugMode) print("Connection failed: $e");
      await speak("connection_failed".tr);
      _isConnecting = false;
      connectedDevice = null;
      update();
    }
  }

  Future<void> disconnect() async {
    if (connectedDevice != null) {
      await _dataSubscription?.cancel();
      await connectedDevice!.disconnect();
      connectedDevice = null;
      _receivedDataMessage = 'No data received yet.';
      update();
      await speak("disconnected_message".tr);
    }
  }

  Future<void> _subscribeToDataCharacteristic(BluetoothDevice device) async {
    final characteristic = await _findServiceCharacteristic(
        device, SERVICE_UUID, DATA_CHAR_UUID);
    if (characteristic != null) {
      await characteristic.setNotifyValue(true);
      _dataSubscription = characteristic.value.listen((value) {
        if (value.isNotEmpty) {
          // ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… utf8 Ø§Ù„Ù…ØªØ§Ø­ Ø¨Ø¹Ø¯ ØªØµØ­ÙŠØ­ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
          final command = utf8.decode(value);
          _handleReceivedData(command);
        }
      });
      if (kDebugMode) print('Subscribed to data char.');
    } else {
      await speak('data_channel_not_found'.tr);
    }
  }

  Future<void> sendMockData(String command) async {
    if (connectedDevice == null) {
      await speak("not_connected_to_device".tr);
      return;
    }
    _receivedDataMessage = 'Sent Mock Command: $command';
    update();
    await speak("data_sent_success".trParams({'command': command}));
  }

  Future<void> sendGestureConfig(Map<String, String> config) async {
    if (connectedDevice == null) {
      await speak("not_connected_to_device".tr);
      return;
    }

    try {
      _gestureConfig = config.map((key, value) => MapEntry(key, ActionTypeExtension.fromCodeName(value)));

      // ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… jsonEncode Ø§Ù„Ù…ØªØ§Ø­ Ø¨Ø¹Ø¯ ØªØµØ­ÙŠØ­ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
      final String configJson = jsonEncode(config);
      // ğŸ’¡ Ù‡Ù†Ø§ ÙŠØ¬Ø¨ Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ© Ø¹Ø¨Ø± BLE

      if (kDebugMode) print("Sending config: $configJson");

      await speak("settings_sent_success".tr);
    } catch (e) {
      if (kDebugMode) print("Error sending config: $e");
      await speak("failed_to_send_settings".tr);
    }
    update();
  }


  void _handleReceivedData(String command) {
    if (kDebugMode) print('Received: $command');
    final spokenMessageKey = _mapCommandToMessage(command);

    final spokenMessage = spokenMessageKey.contains('COMMAND_DEFAULT')
    // ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… .tr Ù‡Ù†Ø§ Ù„Ù„Ø§ÙØªØ±Ø§Ø¶ Ø¨ÙˆØ¬ÙˆØ¯ ØªØ¹Ø±ÙŠØ¨
        ? "command_received".trParams({'command': command}) ?? 'Command received: $command'
        : spokenMessageKey.tr;

    speak(spokenMessage);

    _receivedDataMessage = 'Last Command: $command';
    update();
  }

  String _mapCommandToMessage(String command) {
    switch (command) {
      case 'SOS_ACTIVATED':
        return 'sos_activated_message';
      case 'CALL_CONTACT_L':
        return 'calling_contact';
      case 'BATTERY_LOW':
        return 'battery_low';
      case 'SETTINGS_ACK':
        return 'settings_confirmed';
      default:
        return 'COMMAND_DEFAULT';
    }
  }

  Future<BluetoothCharacteristic?> _findServiceCharacteristic(
      BluetoothDevice device, String serviceUuid, String charUuid) async {

    List<BluetoothService> services;
    try {
      services = await device.discoverServices();
    } catch (e) {
      if (kDebugMode) print("Error discovering services: $e");
      return null;
    }

    final candidates = services
        .where((s) => s.uuid.str.toLowerCase() == serviceUuid.toLowerCase())
        .toList();

    final customService = candidates.isNotEmpty ? candidates.first : null;

    if (customService != null) {
      final charCandidates = customService.characteristics
          .where((c) => c.uuid.str.toLowerCase() == charUuid.toLowerCase())
          .toList();

      return charCandidates.isNotEmpty ? charCandidates.first : null;
    }

    return null;
  }

  @override
  void onClose() {
    if (connectedDevice != null) {
      connectedDevice!.disconnect();
    }
    _sttTimeoutTimer?.cancel();
    _speechToText.stop();
    _dataSubscription?.cancel();
    _flutterTts.stop();
    super.onClose();
  }
}